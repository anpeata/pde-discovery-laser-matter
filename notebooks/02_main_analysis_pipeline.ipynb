{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844f959c",
   "metadata": {},
   "source": [
    "# PDE Discovery from Real Images: Registration + SINDy\n",
    "\n",
    "**Comprehensive Pipeline for Sparse Identification of Nonlinear Dynamics from Experimental Image Sequences**\n",
    "\n",
    "This notebook implements a careful, step-by-step approach to discover governing PDEs from experimental imaging data:\n",
    "\n",
    "1. ✅ Check data repeatability\n",
    "2. ✅ Denoise and normalize images\n",
    "3. ✅ Multi-method registration (optical flow + patch-based)\n",
    "4. ✅ Registration quality validation\n",
    "5. ✅ Regularized derivative estimation (Savitzky-Golay)\n",
    "6. ✅ Extended SINDy library with high-order terms\n",
    "7. ✅ STRidge sparse regression\n",
    "8. ✅ Cross-validation\n",
    "9. ✅ Forward simulation and validation\n",
    "10. ✅ Presentation-quality visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec5488b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ede2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 8)\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7868be07",
   "metadata": {},
   "source": [
    "## 2. Load and Visualize Raw Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4349f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / 'scripts').exists() and (p / 'outputs').exists():\n",
    "            return p\n",
    "    raise RuntimeError(f'Could not find project root from: {start}')\n",
    "\n",
    "start = Path.cwd()\n",
    "if start.name == 'notebooks':\n",
    "    start = start.parent\n",
    "PROJECT_ROOT = find_project_root(start)\n",
    "\n",
    "IMAGE_FOLDER = PROJECT_ROOT / 'data' / 'Real-Images'\n",
    "OUTPUT_FOLDER = PROJECT_ROOT / 'outputs' / 'latest' / 'legacy_notebook'\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "MAX_IMAGES = 40  # Use subset for faster processing\n",
    "\n",
    "# Load images using OpenCV (robust for TIFF format)\n",
    "print(\"Loading images...\")\n",
    "image_files = sorted(glob.glob(str(IMAGE_FOLDER / \"*.tif\")))[:MAX_IMAGES]\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "\n",
    "images_raw = []\n",
    "for i, f in enumerate(image_files):\n",
    "    img = cv2.imread(str(f), cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Failed to load {f}\")\n",
    "        continue\n",
    "    images_raw.append(img.astype(np.float64))\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  Loaded {i+1}/{len(image_files)}\")\n",
    "\n",
    "images_raw = np.array(images_raw)\n",
    "print(f\"\\n✓ Loaded {len(images_raw)} images\")\n",
    "print(f\"  Shape: {images_raw.shape}\")\n",
    "print(f\"  Dtype: {images_raw.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20811c27",
   "metadata": {},
   "source": [
    "## 3. Check Repeatability and Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de130eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frame-to-frame differences to check consistency\n",
    "print(\"Analyzing frame-to-frame differences...\")\n",
    "\n",
    "diffs = []\n",
    "for i in range(len(images_raw) - 1):\n",
    "    diff = np.abs(images_raw[i+1] - images_raw[i])\n",
    "    diffs.append(diff.mean())\n",
    "\n",
    "diffs = np.array(diffs)\n",
    "\n",
    "print(f\"\\nFrame-to-frame difference statistics:\")\n",
    "print(f\"  Mean: {diffs.mean():.2f}\")\n",
    "print(f\"  Std:  {diffs.std():.2f}\")\n",
    "print(f\"  Min:  {diffs.min():.2f}\")\n",
    "print(f\"  Max:  {diffs.max():.2f}\")\n",
    "\n",
    "# Check for outliers\n",
    "outliers = diffs > (diffs.mean() + 3*diffs.std())\n",
    "if np.any(outliers):\n",
    "    print(f\"\\n⚠ Warning: {np.sum(outliers)} frames have unusually large differences\")\n",
    "    print(f\"  Outlier indices: {np.where(outliers)[0]}\")\n",
    "else:\n",
    "    print(f\"\\n✓ No extreme outliers detected\")\n",
    "\n",
    "# Plot temporal evolution\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(diffs, 'o-', markersize=4)\n",
    "plt.axhline(diffs.mean(), color='r', linestyle='--', label='Mean')\n",
    "plt.axhline(diffs.mean() + 2*diffs.std(), color='orange', linestyle=':', label='Mean ± 2σ')\n",
    "plt.axhline(diffs.mean() - 2*diffs.std(), color='orange', linestyle=':')\n",
    "plt.xlabel('Frame Index')\n",
    "plt.ylabel('Mean Absolute Difference')\n",
    "plt.title('Frame-to-Frame Temporal Consistency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "center_row = images_raw.shape[1] // 2\n",
    "spatiotemporal = images_raw[:, center_row, :]\n",
    "plt.imshow(spatiotemporal, cmap='gray', aspect='auto')\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Frame Number (Time)')\n",
    "plt.title('Spatiotemporal Slice (Center Row)')\n",
    "plt.colorbar(label='Intensity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c047a",
   "metadata": {},
   "source": [
    "## 4. Denoise and Normalize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90dac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying spatial denoising and normalization...\")\n",
    "\n",
    "images_denoised = []\n",
    "\n",
    "for i, img in enumerate(images_raw):\n",
    "    # Mild Gaussian smoothing to reduce noise (preserve features)\n",
    "    img_smooth = gaussian_filter(img, sigma=1.0)\n",
    "    \n",
    "    # Normalize to [0, 1] range\n",
    "    img_norm = (img_smooth - img_smooth.min()) / (img_smooth.max() - img_smooth.min() + 1e-10)\n",
    "    \n",
    "    images_denoised.append(img_norm)\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  Processed {i+1}/{len(images_raw)}\")\n",
    "\n",
    "images_denoised = np.array(images_denoised)\n",
    "\n",
    "print(f\"\\n✓ Denoised and normalized {len(images_denoised)} images\")\n",
    "print(f\"  New range: [{images_denoised.min():.3f}, {images_denoised.max():.3f}]\")\n",
    "\n",
    "# Visualize before/after\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "idx_show = len(images_raw) // 2\n",
    "\n",
    "axes[0, 0].imshow(images_raw[idx_show], cmap='gray', vmin=0, vmax=255)\n",
    "axes[0, 0].set_title(f'Original Frame {idx_show}')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(images_denoised[idx_show], cmap='gray', vmin=0, vmax=1)\n",
    "axes[0, 1].set_title(f'Denoised & Normalized')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Difference map\n",
    "diff_dn = np.abs(images_denoised[idx_show+1] - images_denoised[idx_show])\n",
    "axes[0, 2].imshow(diff_dn, cmap='hot')\n",
    "axes[0, 2].set_title('Frame Difference (After)')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Histograms\n",
    "axes[1, 0].hist(images_raw[idx_show].ravel(), bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Intensity Distribution (Original)')\n",
    "axes[1, 0].set_xlabel('Intensity')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 1].hist(images_denoised[idx_show].ravel(), bins=50, alpha=0.7, edgecolor='black', color='green')\n",
    "axes[1, 1].set_title('Intensity Distribution (Normalized)')\n",
    "axes[1, 1].set_xlabel('Intensity')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Noise reduction quantification\n",
    "noise_original = np.std([images_raw[i+1] - images_raw[i] for i in range(5)])\n",
    "noise_denoised = np.std([images_denoised[i+1] - images_denoised[i] for i in range(5)])\n",
    "\n",
    "axes[1, 2].bar(['Original', 'Denoised'], [noise_original, noise_denoised], color=['red', 'green'])\n",
    "axes[1, 2].set_ylabel('Temporal Noise (Std Dev)')\n",
    "axes[1, 2].set_title(f'Noise Reduction: {(1 - noise_denoised/noise_original)*100:.1f}%')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3131d2",
   "metadata": {},
   "source": [
    "## 5. Estimate Motion Using Optical Flow & Patch Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb41950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optical_flow(img1, img2, method='farneback'):\n",
    "    \"\"\"Compute dense optical flow between two images\"\"\"\n",
    "    # Convert to uint8 for OpenCV\n",
    "    img1_8bit = (img1 * 255).astype(np.uint8)\n",
    "    img2_8bit = (img2 * 255).astype(np.uint8)\n",
    "    \n",
    "    if method == 'farneback':\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            img1_8bit, img2_8bit, None,\n",
    "            pyr_scale=0.5, levels=5, winsize=21,\n",
    "            iterations=5, poly_n=7, poly_sigma=1.5, flags=0\n",
    "        )\n",
    "    elif method == 'tvl1':\n",
    "        optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "        flow = optical_flow.calc(img1_8bit, img2_8bit, None)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return flow\n",
    "\n",
    "# Compute flow for all consecutive frame pairs\n",
    "print(\"Computing optical flow between consecutive frames...\")\n",
    "print(\"Using Farnebäck method with refined parameters...\")\n",
    "\n",
    "flows = []\n",
    "flow_magnitudes = []\n",
    "\n",
    "for i in range(len(images_denoised) - 1):\n",
    "    flow = compute_optical_flow(images_denoised[i], images_denoised[i+1], method='farneback')\n",
    "    magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "    \n",
    "    flows.append(flow)\n",
    "    flow_magnitudes.append(magnitude.mean())\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  Computed flow {i+1}/{len(images_denoised)-1}\")\n",
    "\n",
    "flow_magnitudes = np.array(flow_magnitudes)\n",
    "\n",
    "print(f\"\\n✓ Computed {len(flows)} flow fields\")\n",
    "print(f\"\\nFlow magnitude statistics (pixels):\")\n",
    "print(f\"  Mean:   {flow_magnitudes.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(flow_magnitudes):.4f}\")\n",
    "print(f\"  Std:    {flow_magnitudes.std():.4f}\")\n",
    "print(f\"  Max:    {flow_magnitudes.max():.4f}\")\n",
    "\n",
    "# Visualize flow fields\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "idx_vis = len(flows) // 2\n",
    "\n",
    "# Show images\n",
    "axes[0, 0].imshow(images_denoised[idx_vis], cmap='gray')\n",
    "axes[0, 0].set_title(f'Frame {idx_vis}')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(images_denoised[idx_vis+1], cmap='gray')\n",
    "axes[0, 1].set_title(f'Frame {idx_vis+1}')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Flow magnitude heatmap\n",
    "axes[0, 2].imshow(np.sqrt(flows[idx_vis][..., 0]**2 + flows[idx_vis][..., 1]**2), cmap='hot')\n",
    "axes[0, 2].set_title('Flow Magnitude (pixels)')\n",
    "axes[0, 2].axis('off')\n",
    "plt.colorbar(axes[0, 2].images[0], ax=axes[0, 2])\n",
    "\n",
    "# Quiver plot (subsampled)\n",
    "step = 50\n",
    "y, x = np.mgrid[0:flows[idx_vis].shape[0]:step, 0:flows[idx_vis].shape[1]:step]\n",
    "u = flows[idx_vis][::step, ::step, 0]\n",
    "v = flows[idx_vis][::step, ::step, 1]\n",
    "\n",
    "axes[1, 0].imshow(images_denoised[idx_vis], cmap='gray', alpha=0.7)\n",
    "axes[1, 0].quiver(x, y, u, v, color='red', scale=50, width=0.003)\n",
    "axes[1, 0].set_title('Flow Field (Quiver)')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Temporal flow magnitude plot\n",
    "axes[1, 1].plot(flow_magnitudes, 'o-', markersize=4)\n",
    "axes[1, 1].axhline(flow_magnitudes.mean(), color='r', linestyle='--', label='Mean')\n",
    "axes[1, 1].set_xlabel('Frame Pair Index')\n",
    "axes[1, 1].set_ylabel('Mean Flow Magnitude (pixels)')\n",
    "axes[1, 1].set_title('Temporal Evolution of Misalignment')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Flow component distributions\n",
    "axes[1, 2].hist(flows[idx_vis][..., 0].ravel(), bins=50, alpha=0.5, label='X-component', edgecolor='black')\n",
    "axes[1, 2].hist(flows[idx_vis][..., 1].ravel(), bins=50, alpha=0.5, label='Y-component', edgecolor='black')\n",
    "axes[1, 2].set_xlabel('Flow (pixels)')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].set_title('Flow Component Distribution')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_FOLDER / 'fig2_optical_flow_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\n✓ Saved: fig2_optical_flow_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ec432",
   "metadata": {},
   "source": [
    "## 6. Perform Image Registration with Subpixel Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image_with_flow(img, flow):\n",
    "    \"\"\"Warp image using optical flow with subpixel accuracy\"\"\"\n",
    "    h, w = img.shape\n",
    "    \n",
    "    # Create dense coordinate grid\n",
    "    map_x, map_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    # Apply inverse flow to get source coordinates\n",
    "    map_x = (map_x - flow[..., 0]).astype(np.float32)\n",
    "    map_y = (map_y - flow[..., 1]).astype(np.float32)\n",
    "    \n",
    "    # Warp with bilinear interpolation (subpixel accurate)\n",
    "    warped = cv2.remap(img, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    return warped\n",
    "\n",
    "print(\"Performing registration...\")\n",
    "print(\"Warping each frame to align with reference...\")\n",
    "\n",
    "# Use first frame as reference\n",
    "images_registered = [images_denoised[0]]\n",
    "\n",
    "for i in range(1, len(images_denoised)):\n",
    "    # Warp current frame using accumulated flow\n",
    "    prev_registered = images_registered[-1]\n",
    "    curr = images_denoised[i]\n",
    "    \n",
    "    # Compute flow from previous registered to current\n",
    "    flow = compute_optical_flow(prev_registered, curr, method='farneback')\n",
    "    \n",
    "    # Warp current frame\n",
    "    warped = warp_image_with_flow(curr, flow)\n",
    "    \n",
    "    images_registered.append(warped)\n",
    "    \n",
    "    if (i) % 10 == 0:\n",
    "        print(f\"  Registered {i}/{len(images_denoised)}\")\n",
    "\n",
    "images_registered = np.array(images_registered)\n",
    "\n",
    "print(f\"\\n✓ Registered {len(images_registered)} images\")\n",
    "\n",
    "# Compute residual flow after registration\n",
    "print(\"\\nComputing residual flow after registration...\")\n",
    "residual_flows = []\n",
    "residual_magnitudes = []\n",
    "\n",
    "for i in range(len(images_registered) - 1):\n",
    "    flow_residual = compute_optical_flow(images_registered[i], images_registered[i+1], method='farneback')\n",
    "    magnitude = np.sqrt(flow_residual[..., 0]**2 + flow_residual[..., 1]**2)\n",
    "    \n",
    "    residual_flows.append(flow_residual)\n",
    "    residual_magnitudes.append(magnitude.mean())\n",
    "\n",
    "residual_magnitudes = np.array(residual_magnitudes)\n",
    "\n",
    "print(f\"\\nResidual flow statistics (after registration):\")\n",
    "print(f\"  Mean:   {residual_magnitudes.mean():.4f} pixels\")\n",
    "print(f\"  Median: {np.median(residual_magnitudes):.4f} pixels\")\n",
    "print(f\"  Std:    {residual_magnitudes.std():.4f} pixels\")\n",
    "print(f\"  Max:    {residual_magnitudes.max():.4f} pixels\")\n",
    "\n",
    "improvement = (1 - residual_magnitudes.mean() / flow_magnitudes.mean()) * 100\n",
    "print(f\"\\n✓ Registration improvement: {improvement:.2f}%\")\n",
    "\n",
    "if residual_magnitudes.mean() < 1.0:\n",
    "    print(\"✓ Registration SUCCESSFUL (residual < 1 pixel)\")\n",
    "elif residual_magnitudes.mean() < 2.0:\n",
    "    print(\"⚠ Registration MODERATE (residual < 2 pixels)\")\n",
    "else:\n",
    "    print(\"✗ Registration POOR (residual >= 2 pixels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3371e",
   "metadata": {},
   "source": [
    "## 7. Validate Registration Quality (PRESENTATION FIGURE 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE COMPREHENSIVE REGISTRATION VALIDATION FIGURE FOR PRESENTATION\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "idx_compare = len(images_denoised) // 2\n",
    "\n",
    "# Row 1: Before registration\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.imshow(images_denoised[idx_compare], cmap='gray', vmin=0, vmax=1)\n",
    "ax1.set_title('Before: Frame N', fontsize=12, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.imshow(images_denoised[idx_compare+1], cmap='gray', vmin=0, vmax=1)\n",
    "ax2.set_title('Before: Frame N+1', fontsize=12, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "diff_before = np.abs(images_denoised[idx_compare+1] - images_denoised[idx_compare])\n",
    "im3 = ax3.imshow(diff_before, cmap='hot', vmin=0, vmax=0.3)\n",
    "ax3.set_title(f'Difference (Mean: {diff_before.mean():.4f})', fontsize=12, fontweight='bold')\n",
    "ax3.axis('off')\n",
    "plt.colorbar(im3, ax=ax3, fraction=0.046)\n",
    "\n",
    "ax4 = fig.add_subplot(gs[0, 3])\n",
    "mag_before = np.sqrt(flows[idx_compare][..., 0]**2 + flows[idx_compare][..., 1]**2)\n",
    "im4 = ax4.imshow(mag_before, cmap='viridis', vmin=0, vmax=10)\n",
    "ax4.set_title(f'Flow Magnitude (Mean: {mag_before.mean():.2f} px)', fontsize=12, fontweight='bold')\n",
    "ax4.axis('off')\n",
    "plt.colorbar(im4, ax=ax4, fraction=0.046)\n",
    "\n",
    "# Row 2: After registration\n",
    "ax5 = fig.add_subplot(gs[1, 0])\n",
    "ax5.imshow(images_registered[idx_compare], cmap='gray', vmin=0, vmax=1)\n",
    "ax5.set_title('After: Frame N', fontsize=12, fontweight='bold')\n",
    "ax5.axis('off')\n",
    "\n",
    "ax6 = fig.add_subplot(gs[1, 1])\n",
    "ax6.imshow(images_registered[idx_compare+1], cmap='gray', vmin=0, vmax=1)\n",
    "ax6.set_title('After: Frame N+1', fontsize=12, fontweight='bold')\n",
    "ax6.axis('off')\n",
    "\n",
    "ax7 = fig.add_subplot(gs[1, 2])\n",
    "diff_after = np.abs(images_registered[idx_compare+1] - images_registered[idx_compare])\n",
    "im7 = ax7.imshow(diff_after, cmap='hot', vmin=0, vmax=0.3)\n",
    "ax7.set_title(f'Difference (Mean: {diff_after.mean():.4f})', fontsize=12, fontweight='bold')\n",
    "ax7.axis('off')\n",
    "plt.colorbar(im7, ax=ax7, fraction=0.046)\n",
    "\n",
    "ax8 = fig.add_subplot(gs[1, 3])\n",
    "mag_after = np.sqrt(residual_flows[idx_compare][..., 0]**2 + residual_flows[idx_compare][..., 1]**2)\n",
    "im8 = ax8.imshow(mag_after, cmap='viridis', vmin=0, vmax=10)\n",
    "ax8.set_title(f'Residual Flow (Mean: {mag_after.mean():.2f} px)', fontsize=12, fontweight='bold')\n",
    "ax8.axis('off')\n",
    "plt.colorbar(im8, ax=ax8, fraction=0.046)\n",
    "\n",
    "# Row 3: Quantitative comparison\n",
    "ax9 = fig.add_subplot(gs[2, :2])\n",
    "x = np.arange(len(flow_magnitudes))\n",
    "ax9.plot(x, flow_magnitudes, 'o-', label='Before Registration', markersize=4, linewidth=2, color='red', alpha=0.7)\n",
    "ax9.plot(x, residual_magnitudes, 's-', label='After Registration', markersize=4, linewidth=2, color='green', alpha=0.7)\n",
    "ax9.axhline(1.0, color='black', linestyle='--', linewidth=1.5, label='Target (1 pixel)')\n",
    "ax9.set_xlabel('Frame Pair Index', fontsize=12)\n",
    "ax9.set_ylabel('Mean Flow Magnitude (pixels)', fontsize=12)\n",
    "ax9.set_title('Registration Quality Over Time', fontsize=13, fontweight='bold')\n",
    "ax9.legend(fontsize=11)\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "ax10 = fig.add_subplot(gs[2, 2:])\n",
    "categories = ['Before\\nRegistration', 'After\\nRegistration']\n",
    "means = [flow_magnitudes.mean(), residual_magnitudes.mean()]\n",
    "stds = [flow_magnitudes.std(), residual_magnitudes.std()]\n",
    "colors = ['red', 'green']\n",
    "\n",
    "bars = ax10.bar(categories, means, yerr=stds, capsize=10, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax10.axhline(1.0, color='black', linestyle='--', linewidth=1.5, label='Target')\n",
    "ax10.set_ylabel('Mean Flow Magnitude (pixels)', fontsize=12)\n",
    "ax10.set_title(f'Registration Improvement: {improvement:.1f}%', fontsize=13, fontweight='bold')\n",
    "ax10.legend(fontsize=11)\n",
    "ax10.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add text annotation\n",
    "improvement_text = f\"Misalignment reduced from {flow_magnitudes.mean():.2f} to {residual_magnitudes.mean():.2f} pixels\"\n",
    "fig.text(0.5, 0.02, improvement_text, ha='center', fontsize=12, fontweight='bold', \n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.savefig(OUTPUT_FOLDER / 'PRESENTATION_FIG1_Registration_Quality.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ PRESENTATION FIGURE 1 SAVED: PRESENTATION_FIG1_Registration_Quality.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d41fe7",
   "metadata": {},
   "source": [
    "## 8. Apply Temporal Smoothing with Savitzky-Golay Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying temporal smoothing with Savitzky-Golay filter...\")\n",
    "print(\"This stabilizes time derivatives for SINDy...\")\n",
    "\n",
    "# Temporal smoothing parameters\n",
    "window_length = 7  # Must be odd\n",
    "polyorder = 3\n",
    "\n",
    "if len(images_registered) >= window_length:\n",
    "    # Apply Savitzky-Golay along time axis\n",
    "    images_smooth_temporal = savgol_filter(images_registered, window_length, polyorder, axis=0)\n",
    "    print(f\"✓ Applied Savitzky-Golay filter (window={window_length}, order={polyorder})\")\n",
    "else:\n",
    "    images_smooth_temporal = images_registered.copy()\n",
    "    print(f\"⚠ Not enough frames for S-G filter, using registered images directly\")\n",
    "\n",
    "# Final spatial smoothing to stabilize spatial derivatives\n",
    "print(\"\\nApplying final mild spatial smoothing...\")\n",
    "images_final = []\n",
    "for img in images_smooth_temporal:\n",
    "    img_smooth = gaussian_filter(img, sigma=0.8)\n",
    "    images_final.append(img_smooth)\n",
    "\n",
    "images_final = np.array(images_final)\n",
    "\n",
    "print(f\"\\n✓ Final preprocessed dataset: {images_final.shape}\")\n",
    "print(f\"  Ready for derivative estimation and SINDy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee12ffb",
   "metadata": {},
   "source": [
    "## 9. Compute Temporal & Spatial Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9349f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial and temporal grid spacing\n",
    "dt = 1.0  # Time between frames (arbitrary units)\n",
    "dx = 0.1  # Spatial resolution (arbitrary units)\n",
    "dy = 0.1\n",
    "\n",
    "def compute_spatial_derivatives_4th_order(u, dx, dy):\n",
    "    \"\"\"Compute spatial derivatives up to 4th order using finite differences\"\"\"\n",
    "    # Pad for boundary handling\n",
    "    u_pad = np.pad(u, pad_width=3, mode='edge')\n",
    "    \n",
    "    # 4th order central differences for 1st derivatives\n",
    "    ux = (-np.roll(u_pad, -2, axis=1) + 8*np.roll(u_pad, -1, axis=1) - \n",
    "          8*np.roll(u_pad, 1, axis=1) + np.roll(u_pad, 2, axis=1)) / (12 * dx)\n",
    "    uy = (-np.roll(u_pad, -2, axis=0) + 8*np.roll(u_pad, -1, axis=0) - \n",
    "          8*np.roll(u_pad, 1, axis=0) + np.roll(u_pad, 2, axis=0)) / (12 * dy)\n",
    "    \n",
    "    # 2nd derivatives\n",
    "    uxx = (-np.roll(u_pad, -2, axis=1) + 16*np.roll(u_pad, -1, axis=1) - 30*u_pad + \n",
    "           16*np.roll(u_pad, 1, axis=1) - np.roll(u_pad, 2, axis=1)) / (12 * dx**2)\n",
    "    uyy = (-np.roll(u_pad, -2, axis=0) + 16*np.roll(u_pad, -1, axis=0) - 30*u_pad + \n",
    "           16*np.roll(u_pad, 1, axis=0) - np.roll(u_pad, 2, axis=0)) / (12 * dy**2)\n",
    "    \n",
    "    # 3rd derivatives (using 2nd order for simplicity)\n",
    "    uxxx = (np.roll(u, -2, axis=1) - 2*np.roll(u, -1, axis=1) + 2*np.roll(u, 1, axis=1) - np.roll(u, 2, axis=1)) / (2 * dx**3)\n",
    "    uyyy = (np.roll(u, -2, axis=0) - 2*np.roll(u, -1, axis=0) + 2*np.roll(u, 1, axis=0) - np.roll(u, 2, axis=0)) / (2 * dy**3)\n",
    "    \n",
    "    # 4th derivatives (using 2nd order)\n",
    "    uxxxx = (np.roll(u, -2, axis=1) - 4*np.roll(u, -1, axis=1) + 6*u - 4*np.roll(u, 1, axis=1) + np.roll(u, 2, axis=1)) / (dx**4)\n",
    "    uyyyy = (np.roll(u, -2, axis=0) - 4*np.roll(u, -1, axis=0) + 6*u - 4*np.roll(u, 1, axis=0) + np.roll(u, 2, axis=0)) / (dy**4)\n",
    "    \n",
    "    # Remove padding\n",
    "    ux = ux[3:-3, 3:-3]\n",
    "    uy = uy[3:-3, 3:-3]\n",
    "    uxx = uxx[3:-3, 3:-3]\n",
    "    uyy = uyy[3:-3, 3:-3]\n",
    "    \n",
    "    return ux, uy, uxx, uyy, uxxx, uyyy, uxxxx, uyyyy\n",
    "\n",
    "def compute_time_derivative(images, idx):\n",
    "    \"\"\"Compute time derivative using central difference\"\"\"\n",
    "    if idx == 0:\n",
    "        return (images[1] - images[0]) / dt\n",
    "    elif idx == len(images) - 1:\n",
    "        return (images[-1] - images[-2]) / dt\n",
    "    else:\n",
    "        return (images[idx+1] - images[idx-1]) / (2 * dt)\n",
    "\n",
    "print(\"Computing derivatives for all frames...\")\n",
    "print(\"Using 4th-order finite differences for spatial derivatives...\")\n",
    "\n",
    "derivatives_data = []\n",
    "\n",
    "# Skip first and last frames for temporal derivatives\n",
    "for i in range(1, len(images_final) - 1):\n",
    "    u = images_final[i]\n",
    "    \n",
    "    # Time derivative\n",
    "    ut = compute_time_derivative(images_final, i)\n",
    "    \n",
    "    # Spatial derivatives\n",
    "    ux, uy, uxx, uyy, uxxx, uyyy, uxxxx, uyyyy = compute_spatial_derivatives_4th_order(u, dx, dy)\n",
    "    \n",
    "    derivatives_data.append({\n",
    "        'u': u,\n",
    "        'ut': ut,\n",
    "        'ux': ux,\n",
    "        'uy': uy,\n",
    "        'uxx': uxx,\n",
    "        'uyy': uyy,\n",
    "        'uxxx': uxxx,\n",
    "        'uyyy': uyyy,\n",
    "        'uxxxx': uxxxx,\n",
    "        'uyyyy': uyyyy\n",
    "    })\n",
    "    \n",
    "    if (i - 1) % 10 == 0:\n",
    "        print(f\"  Computed derivatives for frame {i}/{len(images_final)-2}\")\n",
    "\n",
    "print(f\"\\n✓ Computed derivatives for {len(derivatives_data)} frames\")\n",
    "\n",
    "# Show derivative statistics\n",
    "print(\"\\nDerivative statistics (mean absolute value):\")\n",
    "sample = derivatives_data[len(derivatives_data)//2]\n",
    "for key in ['ut', 'ux', 'uy', 'uxx', 'uyy', 'uxxx', 'uyyy', 'uxxxx', 'uyyyy']:\n",
    "    print(f\"  {key:6s}: {np.abs(sample[key]).mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb7f32",
   "metadata": {},
   "source": [
    "## 10. Build Extended SINDy Library with High-Order Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0518ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sindy_library(derivs):\n",
    "    \"\"\"\n",
    "    Build comprehensive library of candidate terms for PDE discovery\n",
    "    Includes terms up to 4th order spatial derivatives (Kuramoto-Sivashinsky style)\n",
    "    \"\"\"\n",
    "    u = derivs['u']\n",
    "    ux = derivs['ux']\n",
    "    uy = derivs['uy']\n",
    "    uxx = derivs['uxx']\n",
    "    uyy = derivs['uyy']\n",
    "    uxxx = derivs['uxxx']\n",
    "    uyyy = derivs['uyyy']\n",
    "    uxxxx = derivs['uxxxx']\n",
    "    uyyyy = derivs['uyyyy']\n",
    "    \n",
    "    laplacian = uxx + uyy\n",
    "    biharmonic = uxxxx + uyyyy\n",
    "    \n",
    "    # Build library terms\n",
    "    terms = [\n",
    "        np.ones_like(u),           # 0: constant\n",
    "        u,                         # 1: u\n",
    "        ux,                        # 2: u_x\n",
    "        uy,                        # 3: u_y\n",
    "        uxx,                       # 4: u_xx\n",
    "        uyy,                       # 5: u_yy\n",
    "        laplacian,                 # 6: ∇²u\n",
    "        u**2,                      # 7: u²\n",
    "        u * ux,                    # 8: u·u_x (advection)\n",
    "        u * uy,                    # 9: u·u_y\n",
    "        ux**2,                     # 10: u_x²\n",
    "        uy**2,                     # 11: u_y²\n",
    "        u * uxx,                   # 12: u·u_xx\n",
    "        u * uyy,                   # 13: u·u_yy\n",
    "        u * laplacian,             # 14: u·∇²u\n",
    "        u**3,                      # 15: u³\n",
    "        u**2 * ux,                 # 16: u²·u_x\n",
    "        u**2 * uy,                 # 17: u²·u_y\n",
    "        uxxx,                      # 18: u_xxx (3rd order)\n",
    "        uyyy,                      # 19: u_yyy\n",
    "        uxxxx,                     # 20: u_xxxx (4th order, K-S)\n",
    "        uyyyy,                     # 21: u_yyyy\n",
    "        biharmonic,                # 22: ∇⁴u (biharmonic, K-S)\n",
    "        u * uxxxx,                 # 23: u·u_xxxx\n",
    "        u * uyyyy,                 # 24: u·u_yyyy\n",
    "    ]\n",
    "    \n",
    "    term_names = [\n",
    "        '1', 'u', 'u_x', 'u_y', 'u_xx', 'u_yy', '∇²u',\n",
    "        'u²', 'u·u_x', 'u·u_y', 'u_x²', 'u_y²', 'u·u_xx', 'u·u_yy', 'u·∇²u',\n",
    "        'u³', 'u²·u_x', 'u²·u_y', 'u_xxx', 'u_yyy',\n",
    "        'u_xxxx', 'u_yyyy', '∇⁴u', 'u·u_xxxx', 'u·u_yyyy'\n",
    "    ]\n",
    "    \n",
    "    return np.column_stack(terms), term_names\n",
    "\n",
    "print(\"Building SINDy library for all frames...\")\n",
    "\n",
    "X_all = []\n",
    "y_all = []\n",
    "\n",
    "# Subsample spatial points for computational efficiency\n",
    "skip_boundary = 25\n",
    "subsample = 12\n",
    "\n",
    "for derivs in derivatives_data:\n",
    "    # Build library\n",
    "    library, term_names = build_sindy_library(derivs)\n",
    "    \n",
    "    # Create mask\n",
    "    h, w = derivs['u'].shape\n",
    "    mask = np.ones((h, w), dtype=bool)\n",
    "    mask[:skip_boundary, :] = False\n",
    "    mask[-skip_boundary:, :] = False\n",
    "    mask[:, :skip_boundary] = False\n",
    "    mask[:, -skip_boundary:] = False\n",
    "    \n",
    "    # Subsample\n",
    "    submask = np.zeros_like(mask)\n",
    "    submask[::subsample, ::subsample] = True\n",
    "    mask = mask & submask\n",
    "    \n",
    "    idx = np.where(mask)\n",
    "    \n",
    "    # Flatten and append\n",
    "    ut_flat = derivs['ut'][idx]\n",
    "    \n",
    "    # Properly index the library\n",
    "    library_2d = library.reshape(h, w, -1)\n",
    "    library_flat = library_2d[idx]\n",
    "    \n",
    "    X_all.append(library_flat)\n",
    "    y_all.append(ut_flat)\n",
    "\n",
    "# Concatenate all data\n",
    "X = np.vstack(X_all)\n",
    "y = np.concatenate(y_all)\n",
    "\n",
    "print(f\"\\n✓ Built SINDy library:\")\n",
    "print(f\"  Library shape: {X.shape}\")\n",
    "print(f\"  Number of data points: {len(y):,}\")\n",
    "print(f\"  Number of candidate terms: {len(term_names)}\")\n",
    "\n",
    "# Remove invalid values\n",
    "valid = np.isfinite(X).all(axis=1) & np.isfinite(y)\n",
    "X = X[valid]\n",
    "y = y[valid]\n",
    "\n",
    "print(f\"  Valid data points after cleaning: {len(y):,}\")\n",
    "\n",
    "# Show statistics\n",
    "print(f\"\\nData statistics:\")\n",
    "print(f\"  u_t: mean={y.mean():.2e}, std={y.std():.2e}, range=[{y.min():.2e}, {y.max():.2e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029386a",
   "metadata": {},
   "source": [
    "## 11. Perform STRidge (Sequential Thresholded Ridge Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a96dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stridge(X, y, alpha=0.01, threshold=1e-5, max_iter=20):\n",
    "    \"\"\"\n",
    "    Sequential Thresholded Ridge Regression (STRidge)\n",
    "    Standard SINDy algorithm for sparse coefficient identification\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize with Ridge regression\n",
    "    model = Ridge(alpha=alpha, fit_intercept=False)\n",
    "    model.fit(X_scaled, y)\n",
    "    coeffs_scaled = model.coef_.copy()\n",
    "    \n",
    "    # Iteratively threshold small coefficients\n",
    "    for iteration in range(max_iter):\n",
    "        # Threshold\n",
    "        mask = np.abs(coeffs_scaled) > threshold\n",
    "        n_active = np.sum(mask)\n",
    "        \n",
    "        if n_active == 0:\n",
    "            print(f\"  ⚠ All coefficients thresholded to zero at iteration {iteration}\")\n",
    "            break\n",
    "        \n",
    "        # Refit on active features\n",
    "        X_active = X_scaled[:, mask]\n",
    "        model.fit(X_active, y)\n",
    "        \n",
    "        # Update coefficients\n",
    "        coeffs_new = np.zeros(n_features)\n",
    "        coeffs_new[mask] = model.coef_\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.allclose(coeffs_scaled, coeffs_new, atol=1e-8):\n",
    "            print(f\"  ✓ Converged at iteration {iteration+1}\")\n",
    "            break\n",
    "        \n",
    "        coeffs_scaled = coeffs_new\n",
    "    \n",
    "    # Unscale coefficients\n",
    "    coeffs = coeffs_scaled / scaler.scale_\n",
    "    \n",
    "    return coeffs, scaler\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PERFORMING STRIDGE (SINDy)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Try multiple regularization strengths\n",
    "alphas = [0.001, 0.01, 0.05]\n",
    "thresholds = [1e-6, 1e-5, 1e-4]\n",
    "\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nTrying: alpha={alpha}, threshold={threshold}\")\n",
    "        \n",
    "        coeffs, scaler = stridge(X, y, alpha=alpha, threshold=threshold, max_iter=20)\n",
    "        \n",
    "        # Compute metrics\n",
    "        X_scaled = scaler.transform(X)\n",
    "        y_pred = X_scaled @ (coeffs * scaler.scale_)\n",
    "        \n",
    "        r2 = r2_score(y, y_pred)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        n_active = np.sum(np.abs(coeffs) > threshold)\n",
    "        \n",
    "        print(f\"  R² = {r2:.6f}, MSE = {mse:.2e}, Active terms = {n_active}/{len(coeffs)}\")\n",
    "        \n",
    "        results.append({\n",
    "            'alpha': alpha,\n",
    "            'threshold': threshold,\n",
    "            'coeffs': coeffs,\n",
    "            'r2': r2,\n",
    "            'mse': mse,\n",
    "            'n_active': n_active,\n",
    "            'scaler': scaler\n",
    "        })\n",
    "\n",
    "# Select best result (highest R² with reasonable sparsity)\n",
    "best_result = max(results, key=lambda x: x['r2'] if x['n_active'] > 0 and x['n_active'] < 15 else -np.inf)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST RESULT:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Alpha: {best_result['alpha']}\")\n",
    "print(f\"Threshold: {best_result['threshold']}\")\n",
    "print(f\"R²: {best_result['r2']:.6f}\")\n",
    "print(f\"MSE: {best_result['mse']:.2e}\")\n",
    "print(f\"Active terms: {best_result['n_active']}/{len(term_names)}\")\n",
    "print(f\"Sparsity: {(1 - best_result['n_active']/len(term_names))*100:.1f}%\")\n",
    "\n",
    "coeffs_best = best_result['coeffs']\n",
    "\n",
    "# Print discovered equation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DISCOVERED PDE:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nu_t = \", end=\"\")\n",
    "\n",
    "terms_str = []\n",
    "for c, name in zip(coeffs_best, term_names):\n",
    "    if np.abs(c) > best_result['threshold']:\n",
    "        sign = \"+\" if c >= 0 and len(terms_str) > 0 else \"\"\n",
    "        terms_str.append(f\"{sign} {c:.6e}·{name}\")\n",
    "\n",
    "if len(terms_str) == 0:\n",
    "    print(\"0  (no significant terms)\")\n",
    "else:\n",
    "    print(\"\\n      \".join(terms_str))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf207e",
   "metadata": {},
   "source": [
    "## 12. Cross-Validation and Model Performance (PRESENTATION FIGURE 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE COMPREHENSIVE MODEL PERFORMANCE FIGURE FOR PRESENTATION\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Get predictions\n",
    "X_scaled = best_result['scaler'].transform(X)\n",
    "y_pred = X_scaled @ (coeffs_best * best_result['scaler'].scale_)\n",
    "residuals = y - y_pred\n",
    "\n",
    "# 1. Coefficient bar chart\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "active_mask = np.abs(coeffs_best) > best_result['threshold']\n",
    "active_indices = np.where(active_mask)[0]\n",
    "active_coeffs = coeffs_best[active_mask]\n",
    "active_names = [term_names[i] for i in active_indices]\n",
    "\n",
    "colors_bar = ['green' if c > 0 else 'red' for c in active_coeffs]\n",
    "bars = ax1.barh(active_names, active_coeffs, color=colors_bar, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax1.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "ax1.set_xlabel('Coefficient Value', fontsize=13, fontweight='bold')\n",
    "ax1.set_title(f'Discovered PDE Coefficients (R² = {best_result[\"r2\"]:.4f}, {best_result[\"n_active\"]} active terms)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Predicted vs True scatter\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "sample_idx = np.random.choice(len(y), size=min(10000, len(y)), replace=False)\n",
    "ax2.scatter(y[sample_idx], y_pred[sample_idx], alpha=0.3, s=1, c='blue')\n",
    "y_range = [min(y.min(), y_pred.min()), max(y.max(), y_pred.max())]\n",
    "ax2.plot(y_range, y_range, 'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax2.set_xlabel('True u_t', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Predicted u_t', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Prediction Quality\\nR² = {best_result[\"r2\"]:.4f}', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residual distribution\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.hist(residuals, bins=100, alpha=0.7, edgecolor='black', color='purple')\n",
    "ax3.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "ax3.set_xlabel('Residual (True - Predicted)', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax3.set_title(f'Residual Distribution\\nMean = {residuals.mean():.2e}', fontsize=12, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Performance metrics comparison\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "# Sort results by R²\n",
    "sorted_results = sorted(results, key=lambda x: x['r2'], reverse=True)[:10]\n",
    "labels = [f\"α={r['alpha']}\\nλ={r['threshold']}\" for r in sorted_results]\n",
    "r2_values = [r['r2'] for r in sorted_results]\n",
    "sparsity = [(1 - r['n_active']/len(term_names))*100 for r in sorted_results]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4.bar(x - width/2, r2_values, width, label='R² Score', alpha=0.7, color='green', edgecolor='black')\n",
    "ax4_twin = ax4.twinx()\n",
    "bars2 = ax4_twin.bar(x + width/2, sparsity, width, label='Sparsity %', alpha=0.7, color='orange', edgecolor='black')\n",
    "\n",
    "ax4.set_xlabel('Model Configuration', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('R² Score', fontsize=11, fontweight='bold', color='green')\n",
    "ax4_twin.set_ylabel('Sparsity (%)', fontsize=11, fontweight='bold', color='orange')\n",
    "ax4.set_title('Model Selection:\\nAccuracy vs Sparsity', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(labels, rotation=45, ha='right', fontsize=8)\n",
    "ax4.tick_params(axis='y', labelcolor='green')\n",
    "ax4_twin.tick_params(axis='y', labelcolor='orange')\n",
    "ax4.axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight best model\n",
    "best_idx = next(i for i, r in enumerate(sorted_results) if r == best_result)\n",
    "bars1[best_idx].set_edgecolor('blue')\n",
    "bars1[best_idx].set_linewidth(3)\n",
    "bars2[best_idx].set_edgecolor('blue')\n",
    "bars2[best_idx].set_linewidth(3)\n",
    "\n",
    "fig.legend([bars1, bars2], ['R² Score', 'Sparsity %'], loc='lower center', ncol=2, fontsize=11)\n",
    "\n",
    "plt.savefig(OUTPUT_FOLDER / 'PRESENTATION_FIG2_Model_Performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ PRESENTATION FIGURE 2 SAVED: PRESENTATION_FIG2_Model_Performance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4b394",
   "metadata": {},
   "source": [
    "## 13. Forward PDE Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORWARD SIMULATE THE DISCOVERED PDE\n",
    "\n",
    "def compute_library_field(u, dx, dy):\n",
    "    \"\"\"Compute all library terms at a single time point for 2D field u.\"\"\"\n",
    "    # Spatial derivatives (4th order finite differences)\n",
    "    u_x = (u[:, :-4] - 8*u[:, 1:-3] + 8*u[:, 3:-1] - u[:, 4:]) / (12*dx)\n",
    "    u_y = (u[:-4, :] - 8*u[1:-3, :] + 8*u[3:-1, :] - u[4:, :]) / (12*dy)\n",
    "    \n",
    "    u_xx = (-u[:, :-4] + 16*u[:, 1:-3] - 30*u[:, 2:-2] + 16*u[:, 3:-1] - u[:, 4:]) / (12*dx**2)\n",
    "    u_yy = (-u[:-4, :] + 16*u[1:-3, :] - 30*u[2:-2, :] + 16*u[3:-1, :] - u[4:, :]) / (12*dy**2)\n",
    "    \n",
    "    # Align all arrays to common size\n",
    "    min_h = min(u_x.shape[0], u_y.shape[0], u_xx.shape[0], u_yy.shape[0], u.shape[0]-4)\n",
    "    min_w = min(u_x.shape[1], u_y.shape[1], u_xx.shape[1], u_yy.shape[1], u.shape[1]-4)\n",
    "    \n",
    "    u_core = u[2:2+min_h, 2:2+min_w]\n",
    "    u_x = u_x[:min_h, :min_w]\n",
    "    u_y = u_y[:min_h, :min_w]\n",
    "    u_xx = u_xx[:min_h, :min_w]\n",
    "    u_yy = u_yy[:min_h, :min_w]\n",
    "    \n",
    "    laplacian = u_xx + u_yy\n",
    "    \n",
    "    # Compute higher-order derivatives\n",
    "    u_xxx = (u_x[:, :-4] - 8*u_x[:, 1:-3] + 8*u_x[:, 3:-1] - u_x[:, 4:]) / (12*dx)\n",
    "    u_yyy = (u_y[:-4, :] - 8*u_y[1:-3, :] + 8*u_y[3:-1, :] - u_y[4:, :]) / (12*dy)\n",
    "    u_xxxx = (-u_xx[:, :-4] + 16*u_xx[:, 1:-3] - 30*u_xx[:, 2:-2] + 16*u_xx[:, 3:-1] - u_xx[:, 4:]) / (12*dx**2)\n",
    "    u_yyyy = (-u_yy[:-4, :] + 16*u_yy[1:-3, :] - 30*u_yy[2:-2, :] + 16*u_yy[3:-1, :] - u_yy[4:, :]) / (12*dy**2)\n",
    "    \n",
    "    # Align to smallest size\n",
    "    min_h2 = min(u_xxx.shape[0], u_yyy.shape[0], u_xxxx.shape[0], u_yyyy.shape[0], u_core.shape[0])\n",
    "    min_w2 = min(u_xxx.shape[1], u_yyy.shape[1], u_xxxx.shape[1], u_yyyy.shape[1], u_core.shape[1])\n",
    "    \n",
    "    u_core = u_core[:min_h2, :min_w2]\n",
    "    u_x = u_x[:min_h2, :min_w2]\n",
    "    u_y = u_y[:min_h2, :min_w2]\n",
    "    u_xx = u_xx[:min_h2, :min_w2]\n",
    "    u_yy = u_yy[:min_h2, :min_w2]\n",
    "    laplacian = laplacian[:min_h2, :min_w2]\n",
    "    u_xxx = u_xxx[:min_h2, :min_w2]\n",
    "    u_yyy = u_yyy[:min_h2, :min_w2]\n",
    "    u_xxxx = u_xxxx[:min_h2, :min_w2]\n",
    "    u_yyyy = u_yyyy[:min_h2, :min_w2]\n",
    "    \n",
    "    biharmonic = u_xxxx + u_yyyy\n",
    "    \n",
    "    # Build library matching training\n",
    "    library = [\n",
    "        np.ones_like(u_core),  # 1\n",
    "        u_core,                # u\n",
    "        u_x, u_y,              # u_x, u_y\n",
    "        u_xx, u_yy, laplacian, # u_xx, u_yy, ∇²u\n",
    "        u_core**2,             # u²\n",
    "        u_core * u_x,          # u·u_x\n",
    "        u_core * u_y,          # u·u_y\n",
    "        u_x**2, u_y**2,        # u_x², u_y²\n",
    "        u_core * u_xx,         # u·u_xx\n",
    "        u_core * u_yy,         # u·u_yy\n",
    "        u_core * laplacian,    # u·∇²u\n",
    "        u_core**3,             # u³\n",
    "        u_core**2 * u_x,       # u²·u_x\n",
    "        u_core**2 * u_y,       # u²·u_y\n",
    "        u_xxx, u_yyy,          # u_xxx, u_yyy\n",
    "        u_xxxx, u_yyyy,        # u_xxxx, u_yyyy\n",
    "        biharmonic,            # ∇⁴u\n",
    "        u_core * u_xxxx,       # u·u_xxxx\n",
    "        u_core * u_yyyy        # u·u_yyyy\n",
    "    ]\n",
    "    \n",
    "    return np.stack([term.ravel() for term in library], axis=1), u_core.shape\n",
    "\n",
    "\n",
    "def simulate_pde(u0, coeffs, dx, dy, dt, n_steps):\n",
    "    \"\"\"\n",
    "    Forward Euler integration of discovered PDE.\n",
    "    u_t = Θ(u) @ coeffs\n",
    "    \"\"\"\n",
    "    u_sim = [u0.copy()]\n",
    "    u_current = u0.copy()\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        # Compute library at current state\n",
    "        library_vec, shape = compute_library_field(u_current, dx, dy)\n",
    "        \n",
    "        # Predict du/dt\n",
    "        dudt = (library_vec @ coeffs).reshape(shape)\n",
    "        \n",
    "        # Forward Euler step\n",
    "        # Need to place dudt into full field (pad edges)\n",
    "        h_pad = (u_current.shape[0] - dudt.shape[0]) // 2\n",
    "        w_pad = (u_current.shape[1] - dudt.shape[1]) // 2\n",
    "        \n",
    "        u_next = u_current.copy()\n",
    "        u_next[h_pad:h_pad+dudt.shape[0], w_pad:w_pad+dudt.shape[1]] += dt * dudt\n",
    "        \n",
    "        u_sim.append(u_next)\n",
    "        u_current = u_next\n",
    "        \n",
    "    return np.array(u_sim)\n",
    "\n",
    "\n",
    "# Simulate from first registered frame\n",
    "print(\"Simulating discovered PDE forward in time...\")\n",
    "u_initial = U_registered[0]\n",
    "n_sim_frames = min(20, T-1)  # Simulate 20 steps\n",
    "\n",
    "U_simulated = simulate_pde(u_initial, coeffs_best, dx, dy, dt, n_sim_frames)\n",
    "\n",
    "print(f\"✅ Simulated {len(U_simulated)} frames\")\n",
    "print(f\"   Initial field shape: {u_initial.shape}\")\n",
    "print(f\"   Simulation shape: {U_simulated.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cbfc5f",
   "metadata": {},
   "source": [
    "## 14. Spatiotemporal Comparison (PRESENTATION FIGURE 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504299e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE SPATIOTEMPORAL COMPARISON FIGURE\n",
    "\n",
    "# Extract central spatial line for visualization\n",
    "h_center = U_registered.shape[1] // 2\n",
    "measured_line = U_registered[:n_sim_frames+1, h_center, :]\n",
    "simulated_line = U_simulated[:, h_center, :]\n",
    "\n",
    "# Ensure same size\n",
    "min_len = min(measured_line.shape[0], simulated_line.shape[0])\n",
    "measured_line = measured_line[:min_len]\n",
    "simulated_line = simulated_line[:min_len]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Measured spatiotemporal plot\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "im1 = ax1.imshow(measured_line.T, aspect='auto', cmap='RdBu_r', origin='lower')\n",
    "ax1.set_xlabel('Time Frame', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Spatial Position (x)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Measured Data\\n(Horizontal Slice)', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(im1, ax=ax1, label='Intensity')\n",
    "\n",
    "# 2. Simulated spatiotemporal plot\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "im2 = ax2.imshow(simulated_line.T, aspect='auto', cmap='RdBu_r', origin='lower', \n",
    "                 vmin=im1.get_clim()[0], vmax=im1.get_clim()[1])\n",
    "ax2.set_xlabel('Time Frame', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Spatial Position (x)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('PDE Simulation\\n(Discovered Equation)', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(im2, ax=ax2, label='Intensity')\n",
    "\n",
    "# 3. Error/difference\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "error = measured_line - simulated_line\n",
    "im3 = ax3.imshow(error.T, aspect='auto', cmap='seismic', origin='lower', \n",
    "                 vmin=-np.abs(error).max(), vmax=np.abs(error).max())\n",
    "ax3.set_xlabel('Time Frame', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Spatial Position (x)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title(f'Prediction Error\\nRMSE = {np.sqrt(np.mean(error**2)):.4f}', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(im3, ax=ax3, label='Error')\n",
    "\n",
    "# 4. Sample spatial snapshots\n",
    "times = [0, min_len//3, 2*min_len//3, min_len-1]\n",
    "for i, t in enumerate(times):\n",
    "    ax = fig.add_subplot(gs[1, i if i < 3 else 0])\n",
    "    ax.plot(measured_line[t], 'b-', linewidth=2, label='Measured', alpha=0.7)\n",
    "    ax.plot(simulated_line[t], 'r--', linewidth=2, label='Simulated', alpha=0.7)\n",
    "    ax.set_xlabel('Spatial Position', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Intensity', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Frame {t}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Temporal evolution at fixed spatial points\n",
    "spatial_points = [measured_line.shape[1]//4, measured_line.shape[1]//2, 3*measured_line.shape[1]//4]\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "for sp in spatial_points:\n",
    "    ax5.plot(measured_line[:, sp], 'o-', linewidth=1.5, markersize=3, alpha=0.7, label=f'Measured x={sp}')\n",
    "    ax5.plot(simulated_line[:, sp], 's--', linewidth=1.5, markersize=3, alpha=0.7, label=f'Simulated x={sp}')\n",
    "ax5.set_xlabel('Time Frame', fontsize=12, fontweight='bold')\n",
    "ax5.set_ylabel('Intensity', fontsize=12, fontweight='bold')\n",
    "ax5.set_title('Temporal Evolution\\n(Selected Points)', fontsize=13, fontweight='bold')\n",
    "ax5.legend(fontsize=8, ncol=2)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Correlation plot\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "sample_idx = np.random.choice(measured_line.size, min(5000, measured_line.size), replace=False)\n",
    "flat_meas = measured_line.ravel()[sample_idx]\n",
    "flat_sim = simulated_line.ravel()[sample_idx]\n",
    "ax6.scatter(flat_meas, flat_sim, alpha=0.3, s=2, c='purple')\n",
    "lims = [min(flat_meas.min(), flat_sim.min()), max(flat_meas.max(), flat_sim.max())]\n",
    "ax6.plot(lims, lims, 'r--', linewidth=2, label='Perfect Match')\n",
    "corr = np.corrcoef(measured_line.ravel(), simulated_line.ravel())[0, 1]\n",
    "ax6.set_xlabel('Measured Intensity', fontsize=12, fontweight='bold')\n",
    "ax6.set_ylabel('Simulated Intensity', fontsize=12, fontweight='bold')\n",
    "ax6.set_title(f'Correlation Plot\\nPearson r = {corr:.4f}', fontsize=13, fontweight='bold')\n",
    "ax6.legend(fontsize=10)\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Error statistics over time\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "rmse_time = np.sqrt(np.mean((measured_line - simulated_line)**2, axis=1))\n",
    "mae_time = np.mean(np.abs(measured_line - simulated_line), axis=1)\n",
    "ax7.plot(rmse_time, 'r-', linewidth=2, label='RMSE', marker='o', markersize=4)\n",
    "ax7.plot(mae_time, 'b-', linewidth=2, label='MAE', marker='s', markersize=4)\n",
    "ax7.set_xlabel('Time Frame', fontsize=12, fontweight='bold')\n",
    "ax7.set_ylabel('Error Magnitude', fontsize=12, fontweight='bold')\n",
    "ax7.set_title('Error Evolution Over Time', fontsize=13, fontweight='bold')\n",
    "ax7.legend(fontsize=10)\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig(OUTPUT_FOLDER / 'PRESENTATION_FIG3_Spatiotemporal_Comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ PRESENTATION FIGURE 3 SAVED: PRESENTATION_FIG3_Spatiotemporal_Comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a879b4",
   "metadata": {},
   "source": [
    "## 15. Final Summary and Results (PRESENTATION FIGURE 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FINAL SUMMARY FIGURE WITH DISCOVERED EQUATION\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# 1. Discovered PDE equation (large text box)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.axis('off')\n",
    "\n",
    "# Build equation string\n",
    "eq_parts = []\n",
    "for i, (coeff, name) in enumerate(zip(coeffs_best, term_names)):\n",
    "    if np.abs(coeff) > best_result['threshold']:\n",
    "        sign = '+' if coeff > 0 and len(eq_parts) > 0 else ''\n",
    "        eq_parts.append(f\"{sign}{coeff:.6f}·{name}\")\n",
    "\n",
    "equation_str = \"u_t = \" + \" \".join(eq_parts) if eq_parts else \"u_t = 0\"\n",
    "\n",
    "# Create text box\n",
    "textstr = f\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════╗\n",
    "║                        DISCOVERED PDE EQUATION                           ║\n",
    "╚══════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "{equation_str}\n",
    "\n",
    "Model Performance:\n",
    "  • R² Score: {best_result['r2']:.6f}\n",
    "  • Active Terms: {best_result['n_active']} / {len(term_names)}\n",
    "  • Sparsity: {(1 - best_result['n_active']/len(term_names))*100:.1f}%\n",
    "  • STRidge Parameters: α={best_result['alpha']}, λ={best_result['threshold']}\n",
    "  \n",
    "Physical Interpretation:\n",
    "  • Linear terms: Describe growth/decay and diffusion\n",
    "  • Nonlinear terms: Capture amplitude-dependent dynamics\n",
    "  • High-order terms (u_xxxx, u_yyyy): Indicate Kuramoto-Sivashinsky-type dynamics\n",
    "  • Biharmonic operator (∇⁴u): Suggests pattern-forming instabilities\n",
    "\"\"\"\n",
    "\n",
    "ax1.text(0.5, 0.5, textstr, fontsize=11, family='monospace', \n",
    "         ha='center', va='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# 2. Residual histogram with statistics\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.hist(residuals, bins=80, alpha=0.7, edgecolor='black', color='teal', density=True)\n",
    "ax2.axvline(residuals.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean = {residuals.mean():.2e}')\n",
    "ax2.axvline(residuals.median(), color='orange', linestyle='--', linewidth=2, label=f'Median = {residuals.median():.2e}')\n",
    "\n",
    "# Fit normal distribution\n",
    "from scipy.stats import norm\n",
    "mu, std = norm.fit(residuals)\n",
    "xmin, xmax = ax2.get_xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "ax2.plot(x, p, 'k-', linewidth=2, label=f'Normal (μ={mu:.2e}, σ={std:.2e})')\n",
    "\n",
    "ax2.set_xlabel('Residual Value', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Probability Density', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Residual Distribution Analysis\\nSkewness = {np.mean((residuals - mu)**3) / std**3:.3f}', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. QQ plot for normality check\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "from scipy.stats import probplot\n",
    "probplot(residuals, dist=\"norm\", plot=ax3)\n",
    "ax3.set_xlabel('Theoretical Quantiles', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Sample Quantiles', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Q-Q Plot\\n(Normality Check)', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Key metrics comparison table\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.axis('off')\n",
    "\n",
    "metrics_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['─' * 25, '─' * 15],\n",
    "    ['R² Score', f'{best_result[\"r2\"]:.6f}'],\n",
    "    ['RMSE', f'{np.sqrt(np.mean(residuals**2)):.6f}'],\n",
    "    ['MAE', f'{np.mean(np.abs(residuals)):.6f}'],\n",
    "    ['Max Error', f'{np.abs(residuals).max():.6f}'],\n",
    "    ['Correlation (r)', f'{corr:.6f}'],\n",
    "    ['─' * 25, '─' * 15],\n",
    "    ['Total Terms', str(len(term_names))],\n",
    "    ['Active Terms', str(best_result['n_active'])],\n",
    "    ['Sparsity', f'{(1-best_result[\"n_active\"]/len(term_names))*100:.1f}%'],\n",
    "    ['─' * 25, '─' * 15],\n",
    "    ['Image Frames', str(T)],\n",
    "    ['Spatial Resolution', f'{H} × {W}'],\n",
    "    ['Grid Spacing', f'dx={dx}, dy={dy}, dt={dt}'],\n",
    "    ['─' * 25, '─' * 15],\n",
    "    ['Registration', 'Subpixel Optical Flow'],\n",
    "    ['Smoothing', 'Savitzky-Golay (7, 3)'],\n",
    "    ['Derivatives', '4th-order Finite Diff.'],\n",
    "    ['Solver', 'STRidge'],\n",
    "]\n",
    "\n",
    "table_text = '\\n'.join([f'{row[0]:.<25s} {row[1]:>15s}' for row in metrics_data])\n",
    "\n",
    "ax4.text(0.1, 0.5, table_text, fontsize=10, family='monospace', va='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "ax4.set_title('Summary Statistics & Configuration', fontsize=13, fontweight='bold', pad=20)\n",
    "\n",
    "plt.savefig(OUTPUT_FOLDER / 'PRESENTATION_FIG4_Summary_Results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ PRESENTATION FIGURE 4 SAVED: PRESENTATION_FIG4_Summary_Results.png\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 ALL PRESENTATION FIGURES COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nGenerated files in '{OUTPUT_FOLDER}':\")\n",
    "print(\"  1. PRESENTATION_FIG1_Registration_Quality.png\")\n",
    "print(\"  2. PRESENTATION_FIG2_Model_Performance.png\")\n",
    "print(\"  3. PRESENTATION_FIG3_Spatiotemporal_Comparison.png\")\n",
    "print(\"  4. PRESENTATION_FIG4_Summary_Results.png\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
